{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadce9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import applications as keras_applications\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b2ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_preprocessing\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/jakesanghavi/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from keras_preprocessing) (1.24.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jakesanghavi/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from keras_preprocessing) (1.16.0)\n",
      "Installing collected packages: keras_preprocessing\n",
      "Successfully installed keras_preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = \\\n",
    "    train_datagen.flow_from_directory(\n",
    "'./Headshots',\n",
    "target_size=(224,224),\n",
    "color_mode='rgb',\n",
    "batch_size=32,\n",
    "class_mode='categorical',\n",
    "shuffle=True)\n",
    "\n",
    "train_generator.class_indices.values()\n",
    "# dict_values([0, 1, 2])\n",
    "NO_CLASSES = len(train_generator.class_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc90df8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 11:43:19.746058: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-07 11:43:19.746531: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_vgg16.h5\n",
      "580070376/580070376 [==============================] - 16s 0us/step\n",
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc6/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " fc7/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 2622)              10742334  \n",
      "                                                                 \n",
      " fc8/softmax (Activation)    (None, 2622)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "base_model = VGGFace(include_top=True,\n",
    "    model='vgg16',\n",
    "    input_shape=(224, 224, 3))\n",
    "base_model.summary()\n",
    "\n",
    "print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e6fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
      "58909280/58909280 [==============================] - 2s 0us/step\n",
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "base_model = VGGFace(include_top=False,\n",
    "model='vgg16',\n",
    "input_shape=(224, 224, 3))\n",
    "base_model.summary()\n",
    "print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6d4f4b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NO_CLASSES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# final layer with softmax activation\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m preds \u001b[38;5;241m=\u001b[39m Dense(\u001b[43mNO_CLASSES\u001b[49m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NO_CLASSES' is not defined"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# final layer with softmax activation\n",
    "preds = Dense(NO_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model with the base model's original input and the \n",
    "# new model's output\n",
    "model = Model(inputs = base_model.input, outputs = preds)\n",
    "model.summary()\n",
    "\n",
    "# don't train the first 19 layers - 0..18\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# train the rest of the layers - 19 onwards\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f53318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "  batch_size = 1,\n",
    "  verbose = 1,\n",
    "  epochs = 20)\n",
    "\n",
    "model.save(\n",
    "    'transfer_learning_trained' +\n",
    "    '_face_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5356ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models\n",
    "    import load_model\n",
    "\n",
    "# deletes the existing model\n",
    "del model\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model(\n",
    "    'transfer_learning_trained' +\n",
    "    '_face_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class_dictionary = \\train_generator.class_indices\n",
    "class_dictionary = {\n",
    "    value:key for key, value in class_dictionary.items()\n",
    "}\n",
    "print(class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, 'wb') as f:\n",
    "    pickle.dump(class_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54577fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface import utils\n",
    "\n",
    "# dimension of images\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# load the training labels\n",
    "face_label_filename = 'face-labels.pickle'\n",
    "with open(face_label_filename, \"rb\") as \\\n",
    "    f: class_dictionary = pickle.load(f)\n",
    "\n",
    "class_list = [value for _, value in class_dictionary.items()]\n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657edac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for detecting faces\n",
    "facecascade = \\ cv2.CascadeClassifier(\n",
    "    'haarcascade_frontalface_default.xml')\n",
    "\n",
    "for i in range(1,30): test_image_filename = f'./facetest/face{i}.jpg'\n",
    "\n",
    "# load the image\n",
    "imgtest = cv2.imread(test_image_filename, cv2.IMREAD_COLOR)\n",
    "image_array = np.array(imgtest, \"uint8\")\n",
    "\n",
    "# get the faces detected in the image\n",
    "faces = facecascade.detectMultiScale(imgtest, \n",
    "    scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# if not exactly 1 face is detected, skip this photo\n",
    "if len(faces) != 1: \n",
    "    print(f'---We need exactly 1 face;\n",
    "        photo skipped---')\n",
    "    print()\n",
    "    continue\n",
    "\n",
    "for (x_, y_, w, h) in faces:\n",
    "    # draw the face detected\n",
    "    face_detect = cv2.rectangle(\n",
    "        imgtest, (x_, y_), (x_+w, y_+h), (255, 0, 255), 2)\n",
    "    plt.imshow(face_detect)\n",
    "    plt.show()\n",
    "\n",
    "    # resize the detected face to 224x224\n",
    "    size = (image_width, image_height)\n",
    "    roi = image_array[y_: y_ + h, x_: x_ + w]\n",
    "    resized_image = cv2.resize(roi, size)\n",
    "\n",
    "    # prepare the image for prediction\n",
    "    x = image.img_to_array(resized_image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = utils.preprocess_input(x, version=1)\n",
    "\n",
    "    # making prediction\n",
    "    predicted_prob = model.predict(x)\n",
    "    print(predicted_prob)\n",
    "    print(predicted_prob[0].argmax())\n",
    "    print(\"Predicted face: \" + class_list[predicted_prob[0].argmax()])\n",
    "    print(\"============================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
